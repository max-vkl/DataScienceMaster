{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 6b: Factorization Machines with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yb/mm0hrmlx3g9dv10c735753m00000gn/T/ipykernel_20805/3777615979.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okay bitte :(((("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "!mkdir models\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# complete_train = pd.read_csv('/content/drive/My Drive/_Universität_HPI/Semester 6/Recommenders/Assignments/Assignment 1/data/train.csv')\n",
    "# complete_train_og = complete_train.copy()\n",
    "# test = pd.read_csv('/content/drive/My Drive/_Universität_HPI/Semester 6/Recommenders/Assignments/Assignment 1/givenExample/kaggle_baseline.csv')\n",
    "complete_train = pd.read_csv('train.csv')\n",
    "complete_train_og = complete_train.copy()\n",
    "test = pd.read_csv('kaggle_baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2seq(text, n_genre):\n",
    "    \"\"\" using tokenizer to encoded the multi-level categorical feature\n",
    "    \"\"\"\n",
    "    tokenizer = Tokenizer(lower=True, split='|',filters='', num_words=n_genre)\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    seq = tokenizer.texts_to_sequences(text)\n",
    "    seq = pad_sequences(seq, maxlen=3,padding='post')\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>movie_genre</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2592</td>\n",
       "      <td>Top Gun (1986)</td>\n",
       "      <td>1101</td>\n",
       "      <td>4</td>\n",
       "      <td>Action|Romance</td>\n",
       "      <td>50</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4318</td>\n",
       "      <td>12 Angry Men (1957)</td>\n",
       "      <td>1203</td>\n",
       "      <td>4</td>\n",
       "      <td>Drama</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2756</td>\n",
       "      <td>Robocop 2 (1990)</td>\n",
       "      <td>2986</td>\n",
       "      <td>2</td>\n",
       "      <td>Action|Crime|Sci-Fi</td>\n",
       "      <td>18</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1706</td>\n",
       "      <td>Modern Times (1936)</td>\n",
       "      <td>3462</td>\n",
       "      <td>5</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4813</td>\n",
       "      <td>Milk Money (1994)</td>\n",
       "      <td>276</td>\n",
       "      <td>3</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800162</th>\n",
       "      <td>59</td>\n",
       "      <td>Big Chill, The (1983)</td>\n",
       "      <td>2352</td>\n",
       "      <td>4</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>50</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800163</th>\n",
       "      <td>4458</td>\n",
       "      <td>So I Married an Axe Murderer (1993)</td>\n",
       "      <td>543</td>\n",
       "      <td>4</td>\n",
       "      <td>Comedy|Romance|Thriller</td>\n",
       "      <td>25</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800164</th>\n",
       "      <td>1234</td>\n",
       "      <td>Almost Famous (2000)</td>\n",
       "      <td>3897</td>\n",
       "      <td>4</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>18</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800165</th>\n",
       "      <td>4864</td>\n",
       "      <td>Fish Called Wanda, A (1988)</td>\n",
       "      <td>1079</td>\n",
       "      <td>5</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>18</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800166</th>\n",
       "      <td>605</td>\n",
       "      <td>Mission to Mars (2000)</td>\n",
       "      <td>3354</td>\n",
       "      <td>3</td>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>18</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800167 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                title  movie_id  rating  \\\n",
       "0          2592                       Top Gun (1986)      1101       4   \n",
       "1          4318                  12 Angry Men (1957)      1203       4   \n",
       "2          2756                     Robocop 2 (1990)      2986       2   \n",
       "3          1706                  Modern Times (1936)      3462       5   \n",
       "4          4813                    Milk Money (1994)       276       3   \n",
       "...         ...                                  ...       ...     ...   \n",
       "800162       59                Big Chill, The (1983)      2352       4   \n",
       "800163     4458  So I Married an Axe Murderer (1993)       543       4   \n",
       "800164     1234                 Almost Famous (2000)      3897       4   \n",
       "800165     4864          Fish Called Wanda, A (1988)      1079       5   \n",
       "800166      605               Mission to Mars (2000)      3354       3   \n",
       "\n",
       "                    movie_genre  age sex  \n",
       "0                Action|Romance   50   M  \n",
       "1                         Drama   25   M  \n",
       "2           Action|Crime|Sci-Fi   18   M  \n",
       "3                        Comedy   25   M  \n",
       "4                Comedy|Romance   35   F  \n",
       "...                         ...  ...  ..  \n",
       "800162             Comedy|Drama   50   F  \n",
       "800163  Comedy|Romance|Thriller   25   F  \n",
       "800164             Comedy|Drama   18   M  \n",
       "800165                   Comedy   18   M  \n",
       "800166                   Sci-Fi   18   F  \n",
       "\n",
       "[800167 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = complete_train.copy()\n",
    "df = df.rename(columns={\"release_date\": \"movie_genre\", \"age\": \"sex\", \"sex\": \"age\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genre = 18\n",
    "df['movie_genre'] = text2seq(df['movie_genre'].values, n_genre=n_genre).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-37d2d3fd-139f-476f-aee9-86000751f26b\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>movie_genre</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2592</td>\n",
       "      <td>Top Gun (1986)</td>\n",
       "      <td>1101</td>\n",
       "      <td>4</td>\n",
       "      <td>[3, 6, 0]</td>\n",
       "      <td>50</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4318</td>\n",
       "      <td>12 Angry Men (1957)</td>\n",
       "      <td>1203</td>\n",
       "      <td>4</td>\n",
       "      <td>[2, 0, 0]</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2756</td>\n",
       "      <td>Robocop 2 (1990)</td>\n",
       "      <td>2986</td>\n",
       "      <td>2</td>\n",
       "      <td>[3, 8, 5]</td>\n",
       "      <td>18</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1706</td>\n",
       "      <td>Modern Times (1936)</td>\n",
       "      <td>3462</td>\n",
       "      <td>5</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4813</td>\n",
       "      <td>Milk Money (1994)</td>\n",
       "      <td>276</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 6, 0]</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800162</th>\n",
       "      <td>59</td>\n",
       "      <td>Big Chill, The (1983)</td>\n",
       "      <td>2352</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 2, 0]</td>\n",
       "      <td>50</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800163</th>\n",
       "      <td>4458</td>\n",
       "      <td>So I Married an Axe Murderer (1993)</td>\n",
       "      <td>543</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 6, 4]</td>\n",
       "      <td>25</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800164</th>\n",
       "      <td>1234</td>\n",
       "      <td>Almost Famous (2000)</td>\n",
       "      <td>3897</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 2, 0]</td>\n",
       "      <td>18</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800165</th>\n",
       "      <td>4864</td>\n",
       "      <td>Fish Called Wanda, A (1988)</td>\n",
       "      <td>1079</td>\n",
       "      <td>5</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>18</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800166</th>\n",
       "      <td>605</td>\n",
       "      <td>Mission to Mars (2000)</td>\n",
       "      <td>3354</td>\n",
       "      <td>3</td>\n",
       "      <td>[5, 0, 0]</td>\n",
       "      <td>18</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800167 rows × 7 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37d2d3fd-139f-476f-aee9-86000751f26b')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-37d2d3fd-139f-476f-aee9-86000751f26b button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-37d2d3fd-139f-476f-aee9-86000751f26b');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-7ad2c758-251f-4525-98e6-6705456a1dc3\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7ad2c758-251f-4525-98e6-6705456a1dc3')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-7ad2c758-251f-4525-98e6-6705456a1dc3 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "        user_id                                title  movie_id  rating  \\\n",
       "0          2592                       Top Gun (1986)      1101       4   \n",
       "1          4318                  12 Angry Men (1957)      1203       4   \n",
       "2          2756                     Robocop 2 (1990)      2986       2   \n",
       "3          1706                  Modern Times (1936)      3462       5   \n",
       "4          4813                    Milk Money (1994)       276       3   \n",
       "...         ...                                  ...       ...     ...   \n",
       "800162       59                Big Chill, The (1983)      2352       4   \n",
       "800163     4458  So I Married an Axe Murderer (1993)       543       4   \n",
       "800164     1234                 Almost Famous (2000)      3897       4   \n",
       "800165     4864          Fish Called Wanda, A (1988)      1079       5   \n",
       "800166      605               Mission to Mars (2000)      3354       3   \n",
       "\n",
       "       movie_genre  age sex  \n",
       "0        [3, 6, 0]   50   M  \n",
       "1        [2, 0, 0]   25   M  \n",
       "2        [3, 8, 5]   18   M  \n",
       "3        [1, 0, 0]   25   M  \n",
       "4        [1, 6, 0]   35   F  \n",
       "...            ...  ...  ..  \n",
       "800162   [1, 2, 0]   50   F  \n",
       "800163   [1, 6, 4]   25   F  \n",
       "800164   [1, 2, 0]   18   M  \n",
       "800165   [1, 0, 0]   18   M  \n",
       "800166   [5, 0, 0]   18   F  \n",
       "\n",
       "[800167 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(df, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "def define_input_layers():\n",
    "    # numerical features\n",
    "    fea3_input = Input((1,), name = 'input_fea3')\n",
    "    num_inputs = [fea3_input]\n",
    "    # single level categorical features\n",
    "    uid_input = Input((1,), name = 'input_uid') #user_id\n",
    "    mid_input = Input((1,), name= 'input_mid')  #movie_id\n",
    "    cat_sl_inputs = [uid_input, mid_input]\n",
    "\n",
    "    # multi level categorical features (with 3 genres at most)\n",
    "    genre_input = Input((3,), name = 'input_genre')\n",
    "    cat_ml_inputs = [genre_input]\n",
    "\n",
    "    inputs = num_inputs + cat_sl_inputs + cat_ml_inputs\n",
    "\n",
    "    return inputs\n",
    "\n",
    "inputs = define_input_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/layer.py:845: UserWarning: Layer 'embed_1d_mean' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def Tensor_Mean_Pooling(name = 'mean_pooling', keepdims = False):\n",
    "    return Lambda(lambda x: K.mean(x, axis = 1, keepdims=keepdims), name = name)\n",
    "\n",
    "def fm_1d(inputs, n_uid, n_mid, n_genre):\n",
    "\n",
    "    # user feat3 + user embedding + movie embedding + genre embedding\n",
    "    fea3_input, uid_input, mid_input, genre_input = inputs\n",
    "\n",
    "    # all tensors are reshape to (None, 1)\n",
    "    num_dense_1d = [Dense(1, name = 'num_dense_1d_fea4')(fea3_input)]\n",
    "    cat_sl_embed_1d = [Embedding(n_uid + 1, 1, name = 'cat_embed_1d_uid')(uid_input),\n",
    "                        Embedding(n_mid + 1, 1, name = 'cat_embed_1d_mid')(mid_input)]\n",
    "    cat_ml_embed_1d = [Embedding(n_genre + 1, 1, mask_zero=True, name = 'cat_embed_1d_genre')(genre_input)]\n",
    "\n",
    "    cat_sl_embed_1d = [Reshape((1,))(i) for i in cat_sl_embed_1d]\n",
    "    cat_ml_embed_1d = [Tensor_Mean_Pooling(name = 'embed_1d_mean')(i) for i in cat_ml_embed_1d]\n",
    "\n",
    "    # add all tensors\n",
    "    y_fm_1d = Add(name = 'fm_1d_output')(num_dense_1d + cat_sl_embed_1d + cat_ml_embed_1d)\n",
    "\n",
    "    return y_fm_1d\n",
    "\n",
    "y_1d = fm_1d(inputs, 10, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fm_2d(inputs, n_uid, n_mid, n_genre, k):\n",
    "\n",
    "    fea3_input, uid_input, mid_input, genre_input = inputs\n",
    "\n",
    "    num_dense_2d = [Dense(k, name = 'num_dense_2d_fea3')(fea3_input)] # shape (None, k)\n",
    "    num_dense_2d = [Reshape((1,k))(i) for i in num_dense_2d] # shape (None, 1, k)\n",
    "\n",
    "    cat_sl_embed_2d = [Embedding(n_uid + 1, k, name = 'cat_embed_2d_uid')(uid_input),\n",
    "                       Embedding(n_mid + 1, k, name = 'cat_embed_2d_mid')(mid_input)] # shape (None, 1, k)\n",
    "\n",
    "    cat_ml_embed_2d = [Embedding(n_genre + 1, k, name = 'cat_embed_2d_genre')(genre_input)] # shape (None, 3, k)\n",
    "    cat_ml_embed_2d = [Tensor_Mean_Pooling(name = 'cat_embed_2d_genure_mean', keepdims=True)(i) for i in cat_ml_embed_2d] # shape (None, 1, k)\n",
    "\n",
    "    # concatenate all 2d embed layers => (None, ?, k)\n",
    "    embed_2d = Concatenate(axis=1, name = 'concat_embed_2d')(num_dense_2d + cat_sl_embed_2d + cat_ml_embed_2d)\n",
    "\n",
    "    # calcuate the interactions by simplication\n",
    "    # sum of (x1*x2) = sum of (0.5*[(xi)^2 - (xi^2)])\n",
    "    tensor_sum = Lambda(lambda x: K.sum(x, axis = 1), name = 'sum_of_tensors')\n",
    "    tensor_square = Lambda(lambda x: K.square(x), name = 'square_of_tensors')\n",
    "\n",
    "    sum_of_embed = tensor_sum(embed_2d)\n",
    "    square_of_embed = tensor_square(embed_2d)\n",
    "\n",
    "    square_of_sum = Multiply()([sum_of_embed, sum_of_embed])\n",
    "    sum_of_square = tensor_sum(square_of_embed)\n",
    "\n",
    "    sub = Subtract()([square_of_sum, sum_of_square])\n",
    "    sub = Lambda(lambda x: x*0.5)(sub)\n",
    "    y_fm_2d = Reshape((1,), name = 'fm_2d_output')(tensor_sum(sub))\n",
    "\n",
    "    return y_fm_2d, embed_2d\n",
    "\n",
    "y_fm2_d, embed_2d = fm_2d(inputs, 10, 10, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fm_model(n_uid, n_mid, n_genre, k, dnn_dr):\n",
    "\n",
    "    inputs = define_input_layers()\n",
    "\n",
    "    y_fm_1d = fm_1d(inputs, n_uid, n_mid, n_genre)\n",
    "    y_fm_2d, embed_2d = fm_2d(inputs, n_uid, n_mid, n_genre, k)\n",
    "\n",
    "\n",
    "    # combinded deep and fm parts\n",
    "    y = Concatenate()([y_fm_1d, y_fm_2d])\n",
    "    y = Dense(1, name = 'fm_output')(y)\n",
    "\n",
    "    fm_model_1d = Model(inputs, y_fm_1d)\n",
    "    fm_model_2d = Model(inputs, y_fm_2d)\n",
    "    fm_model = Model(inputs, y)\n",
    "\n",
    "    return fm_model_1d, fm_model_2d, fm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/layer.py:845: UserWarning: Layer 'embed_1d_mean' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_uid': df['user_id'].max(),\n",
    "    'n_mid': df['movie_id'].max(),\n",
    "    'n_genre': 18,\n",
    "    'k':20,\n",
    "    'dnn_dr': 0.5\n",
    "}\n",
    "\n",
    "fm_model_1d, fm_model_2d, fm_model = fm_model(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2xy(ratings):\n",
    "    x = [df['age'].values,\n",
    "         df['user_id'].values,\n",
    "         df['movie_id'].values,\n",
    "         np.concatenate(df['movie_genre'].values).reshape(-1,3)]\n",
    "    y = df['rating'].values\n",
    "    return x,y\n",
    "\n",
    "train_x, train_y = df2xy(train)\n",
    "valid_x, valid_y = df2xy(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2.7122 - val_loss: 1.0261\n",
      "Epoch 2/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0087 - val_loss: 0.9263\n",
      "Epoch 3/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.9275 - val_loss: 0.8745\n",
      "Epoch 4/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.8813 - val_loss: 0.8432\n",
      "Epoch 5/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.8553 - val_loss: 0.8237\n",
      "Epoch 6/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.8364 - val_loss: 0.8114\n",
      "Epoch 7/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.8225 - val_loss: 0.8038\n",
      "Epoch 8/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8138 - val_loss: 0.7975\n",
      "Epoch 9/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.8077 - val_loss: 0.7936\n",
      "Epoch 10/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.8043 - val_loss: 0.7897\n",
      "Epoch 11/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7977 - val_loss: 0.7906\n",
      "Epoch 12/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7953 - val_loss: 0.7862\n",
      "Epoch 13/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7948 - val_loss: 0.7786\n",
      "Epoch 14/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7890 - val_loss: 0.7751\n",
      "Epoch 15/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7841 - val_loss: 0.7721\n",
      "Epoch 16/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7810 - val_loss: 0.7668\n",
      "Epoch 17/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7759 - val_loss: 0.7605\n",
      "Epoch 18/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7695 - val_loss: 0.7539\n",
      "Epoch 19/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7601 - val_loss: 0.7459\n",
      "Epoch 20/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7539 - val_loss: 0.7376\n",
      "Epoch 21/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.7469 - val_loss: 0.7303\n",
      "Epoch 22/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7361 - val_loss: 0.7200\n",
      "Epoch 23/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7291 - val_loss: 0.7106\n",
      "Epoch 24/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7198 - val_loss: 0.7013\n",
      "Epoch 25/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7098 - val_loss: 0.6910\n",
      "Epoch 26/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6990 - val_loss: 0.6806\n",
      "Epoch 27/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6883 - val_loss: 0.6698\n",
      "Epoch 28/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6757 - val_loss: 0.6585\n",
      "Epoch 29/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.6656 - val_loss: 0.6504\n",
      "Epoch 30/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6566 - val_loss: 0.6395\n",
      "Epoch 31/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6490 - val_loss: 0.6345\n",
      "Epoch 32/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6408 - val_loss: 0.6243\n",
      "Epoch 33/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6321 - val_loss: 0.6200\n",
      "Epoch 34/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6266 - val_loss: 0.6137\n",
      "Epoch 35/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6181 - val_loss: 0.6057\n",
      "Epoch 36/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6145 - val_loss: 0.6002\n",
      "Epoch 37/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6079 - val_loss: 0.5923\n",
      "Epoch 38/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.6006 - val_loss: 0.5875\n",
      "Epoch 39/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5950 - val_loss: 0.5822\n",
      "Epoch 40/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5892 - val_loss: 0.5764\n",
      "Epoch 41/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5849 - val_loss: 0.5726\n",
      "Epoch 42/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5786 - val_loss: 0.5663\n",
      "Epoch 43/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.5755 - val_loss: 0.5626\n",
      "Epoch 44/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5702 - val_loss: 0.5566\n",
      "Epoch 45/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5671 - val_loss: 0.5526\n",
      "Epoch 46/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5596 - val_loss: 0.5488\n",
      "Epoch 47/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5553 - val_loss: 0.5462\n",
      "Epoch 48/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5552 - val_loss: 0.5400\n",
      "Epoch 49/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5487 - val_loss: 0.5383\n",
      "Epoch 50/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5454 - val_loss: 0.5340\n",
      "Epoch 51/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5434 - val_loss: 0.5304\n",
      "Epoch 52/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5397 - val_loss: 0.5286\n",
      "Epoch 53/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5372 - val_loss: 0.5294\n",
      "Epoch 54/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5350 - val_loss: 0.5233\n",
      "Epoch 55/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5308 - val_loss: 0.5212\n",
      "Epoch 56/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5290 - val_loss: 0.5193\n",
      "Epoch 57/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.5285 - val_loss: 0.5163\n",
      "Epoch 58/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.5265 - val_loss: 0.5153\n",
      "Epoch 59/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.5236 - val_loss: 0.5147\n",
      "Epoch 60/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5213 - val_loss: 0.5125\n",
      "Epoch 61/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5208 - val_loss: 0.5096\n",
      "Epoch 62/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5208 - val_loss: 0.5111\n",
      "Epoch 63/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.5183 - val_loss: 0.5086\n",
      "Epoch 64/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.5170 - val_loss: 0.5063\n",
      "Epoch 65/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5153 - val_loss: 0.5049\n",
      "Epoch 66/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5127 - val_loss: 0.5036\n",
      "Epoch 67/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5119 - val_loss: 0.5023\n",
      "Epoch 68/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5094 - val_loss: 0.5011\n",
      "Epoch 69/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5093 - val_loss: 0.5005\n",
      "Epoch 70/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5079 - val_loss: 0.4992\n",
      "Epoch 71/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.5081 - val_loss: 0.4973\n",
      "Epoch 72/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5055 - val_loss: 0.4961\n",
      "Epoch 73/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5037 - val_loss: 0.4957\n",
      "Epoch 74/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5031 - val_loss: 0.4936\n",
      "Epoch 75/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5022 - val_loss: 0.4937\n",
      "Epoch 76/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5017 - val_loss: 0.4930\n",
      "Epoch 77/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5004 - val_loss: 0.4920\n",
      "Epoch 78/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4996 - val_loss: 0.4911\n",
      "Epoch 79/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4986 - val_loss: 0.4888\n",
      "Epoch 80/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4979 - val_loss: 0.4890\n",
      "Epoch 81/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4951 - val_loss: 0.4870\n",
      "Epoch 82/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4958 - val_loss: 0.4872\n",
      "Epoch 83/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4953 - val_loss: 0.4841\n",
      "Epoch 84/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4933 - val_loss: 0.4840\n",
      "Epoch 85/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4934 - val_loss: 0.4834\n",
      "Epoch 86/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4924 - val_loss: 0.4821\n",
      "Epoch 87/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4916 - val_loss: 0.4834\n",
      "Epoch 88/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4908 - val_loss: 0.4816\n",
      "Epoch 89/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4891 - val_loss: 0.4805\n",
      "Epoch 90/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4887 - val_loss: 0.4789\n",
      "Epoch 91/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4877 - val_loss: 0.4796\n",
      "Epoch 92/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4866 - val_loss: 0.4787\n",
      "Epoch 93/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4856 - val_loss: 0.4757\n",
      "Epoch 94/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4844 - val_loss: 0.4755\n",
      "Epoch 95/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.4840 - val_loss: 0.4740\n",
      "Epoch 96/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4839 - val_loss: 0.4738\n",
      "Epoch 97/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4813 - val_loss: 0.4728\n",
      "Epoch 98/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4817 - val_loss: 0.4719\n",
      "Epoch 99/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4807 - val_loss: 0.4713\n",
      "Epoch 100/100\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4800 - val_loss: 0.4721\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import  EarlyStopping, ModelCheckpoint\n",
    "fm_model_2d.compile(\n",
    "    loss=tf.keras.losses.MeanSquaredError(), optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
    ")\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "model_ckp = ModelCheckpoint(filepath='./models/deepfm.weights.h5',\n",
    "                            monitor='val_loss',\n",
    "                            save_weights_only=True,\n",
    "                            save_best_only=True)\n",
    "callbacks = [model_ckp,early_stop]\n",
    "train_history = fm_model_2d.fit(train_x, train_y,\n",
    "                                  epochs=100, batch_size=2048,\n",
    "                                  validation_data=(valid_x, valid_y),\n",
    "                                  callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "391/391 [==============================] - 38s 91ms/step - loss: 0.4712 - val_loss: 0.4561\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 0.4701 - val_loss: 0.4562\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 0.4697 - val_loss: 0.4552\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.4692 - val_loss: 0.4566\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.4688 - val_loss: 0.4550\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 0.4685 - val_loss: 0.4550\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.4681 - val_loss: 0.4558\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.4677 - val_loss: 0.4531\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.4671 - val_loss: 0.4533\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.4665 - val_loss: 0.4520\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 0.4666 - val_loss: 0.4526\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.4662 - val_loss: 0.4528\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.4656 - val_loss: 0.4517\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.4654 - val_loss: 0.4516\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.4651 - val_loss: 0.4505\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.4648 - val_loss: 0.4522\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.4645 - val_loss: 0.4497\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.4638 - val_loss: 0.4492\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.4637 - val_loss: 0.4504\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.4633 - val_loss: 0.4509\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.4631 - val_loss: 0.4496\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train  model\n",
    "fm_model.compile(\n",
    "    loss=tf.keras.losses.MeanSquaredError(), optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
    ")\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "model_ckp = ModelCheckpoint(filepath='./models/deepfm_weights.h5',\n",
    "                            monitor='val_loss',\n",
    "                            save_weights_only=True,\n",
    "                            save_best_only=True)\n",
    "callbacks = [model_ckp,early_stop]\n",
    "train_history = fm_model.fit(train_x, train_y,\n",
    "                                  epochs=100, batch_size=2048,\n",
    "                                  validation_data=(valid_x, valid_y),\n",
    "                                  callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.4588"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "391/391 [==============================] - 20s 49ms/step - loss: 140.3054 - val_loss: 43.0128\n",
      "Epoch 2/30\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 17.0158 - val_loss: 5.3378\n",
      "Epoch 3/30\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 3.8143 - val_loss: 3.2096\n",
      "Epoch 4/30\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 3.0070 - val_loss: 2.8141\n",
      "Epoch 5/30\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 2.6332 - val_loss: 2.4516\n",
      "Epoch 6/30\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 2.2832 - val_loss: 2.1162\n",
      "Epoch 7/30\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 1.9659 - val_loss: 1.8188\n",
      "Epoch 8/30\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.6905 - val_loss: 1.5662\n",
      "Epoch 9/30\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.4615 - val_loss: 1.3610\n",
      "Epoch 10/30\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 1.2794 - val_loss: 1.2016\n",
      "Epoch 11/30\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 1.1407 - val_loss: 1.0828\n",
      "Epoch 12/30\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1.0394 - val_loss: 0.9977\n",
      "Epoch 13/30\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.9679 - val_loss: 0.9384\n",
      "Epoch 14/30\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.9186 - val_loss: 0.8980\n",
      "Epoch 15/30\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.8851 - val_loss: 0.8705\n",
      "Epoch 16/30\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.8624 - val_loss: 0.8518\n",
      "Epoch 17/30\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.8468 - val_loss: 0.8389\n",
      "Epoch 18/30\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.8360 - val_loss: 0.8298\n",
      "Epoch 19/30\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.8284 - val_loss: 0.8234\n",
      "Epoch 20/30\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.8230 - val_loss: 0.8188\n",
      "Epoch 21/30\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.8191 - val_loss: 0.8155\n",
      "Epoch 22/30\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.8162 - val_loss: 0.8130\n",
      "Epoch 23/30\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.8141 - val_loss: 0.8111\n",
      "Epoch 24/30\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.8125 - val_loss: 0.8097\n",
      "Epoch 25/30\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.8113 - val_loss: 0.8086\n",
      "Epoch 26/30\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.8104 - val_loss: 0.8078\n",
      "Epoch 27/30\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.8097 - val_loss: 0.8072\n",
      "Epoch 28/30\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.8091 - val_loss: 0.8070\n",
      "Epoch 29/30\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.8087 - val_loss: 0.8072\n",
      "Epoch 30/30\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.8084 - val_loss: 0.8059\n"
     ]
    }
   ],
   "source": [
    "fm_model_1d.compile(\n",
    "    loss=tf.keras.losses.MeanSquaredError(), optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
    ")\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "model_ckp = ModelCheckpoint(filepath='./models/deepfm_weights.h5',\n",
    "                            monitor='val_loss',\n",
    "                            save_weights_only=True,\n",
    "                            save_best_only=True)\n",
    "callbacks = [model_ckp,early_stop]\n",
    "train_history = fm_model_1d.fit(train_x, train_y,\n",
    "                                  epochs=100, batch_size=2048,\n",
    "                                  validation_data=(valid_x, valid_y),\n",
    "                                  callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "391/391 [==============================] - 19s 46ms/step - loss: 1.9383 - val_loss: 0.7073\n",
      "Epoch 2/40\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 0.7165 - val_loss: 0.6988\n",
      "Epoch 3/40\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.7111 - val_loss: 0.6936\n",
      "Epoch 4/40\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 0.7065 - val_loss: 0.6897\n",
      "Epoch 5/40\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.7016 - val_loss: 0.6848\n",
      "Epoch 6/40\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6968 - val_loss: 0.6793\n",
      "Epoch 7/40\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.6918 - val_loss: 0.6745\n",
      "Epoch 8/40\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.6867 - val_loss: 0.6707\n",
      "Epoch 9/40\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.6821 - val_loss: 0.6644\n",
      "Epoch 10/40\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.6766 - val_loss: 0.6595\n",
      "Epoch 11/40\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.6713 - val_loss: 0.6545\n",
      "Epoch 12/40\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6660 - val_loss: 0.6494\n",
      "Epoch 13/40\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.6599 - val_loss: 0.6429\n",
      "Epoch 14/40\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.6539 - val_loss: 0.6371\n",
      "Epoch 15/40\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.6481 - val_loss: 0.6290\n",
      "Epoch 16/40\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6415 - val_loss: 0.6268\n",
      "Epoch 17/40\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6351 - val_loss: 0.6168\n",
      "Epoch 18/40\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.6289 - val_loss: 0.6099\n",
      "Epoch 19/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.6229 - val_loss: 0.6056\n",
      "Epoch 20/40\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6174 - val_loss: 0.5982\n",
      "Epoch 21/40\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6115 - val_loss: 0.5936\n",
      "Epoch 22/40\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.6061 - val_loss: 0.5899\n",
      "Epoch 23/40\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6012 - val_loss: 0.5837\n",
      "Epoch 24/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5964 - val_loss: 0.5806\n",
      "Epoch 25/40\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5919 - val_loss: 0.5745\n",
      "Epoch 26/40\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.5875 - val_loss: 0.5691\n",
      "Epoch 27/40\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.5835 - val_loss: 0.5656\n",
      "Epoch 28/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5798 - val_loss: 0.5638\n",
      "Epoch 29/40\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.5754 - val_loss: 0.5575\n",
      "Epoch 30/40\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.5711 - val_loss: 0.5537\n",
      "Epoch 31/40\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5676 - val_loss: 0.5499\n",
      "Epoch 32/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5640 - val_loss: 0.5471\n",
      "Epoch 33/40\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.5606 - val_loss: 0.5432\n",
      "Epoch 34/40\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.5572 - val_loss: 0.5408\n",
      "Epoch 35/40\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.5539 - val_loss: 0.5371\n",
      "Epoch 36/40\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.5507 - val_loss: 0.5333\n",
      "Epoch 37/40\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.5476 - val_loss: 0.5316\n",
      "Epoch 38/40\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5453 - val_loss: 0.5314\n",
      "Epoch 39/40\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5420 - val_loss: 0.5249\n",
      "Epoch 40/40\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5394 - val_loss: 0.5217\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
